{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USAYnCRGJO2i"
      },
      "source": [
        "# Word Embeddings\n",
        "* Text Retrieval and Mining, BSc BAN, 2023-2024\n",
        "* Author: [Julien Rossi](mailto:j.rossi@uva.nl)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GloVe"
      ],
      "metadata": {
        "id": "aIJQ0v6eQrHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe is a model described by Pennington et al. in 2014\n",
        "* Pennington et al. (2014) \"GloVe: Global Vectors for Word Representation\" [Link](https://nlp.stanford.edu/pubs/glove.pdf)\n",
        "\n",
        "GloVe is a model where the counts in the word co-occurence matrix are predicted from the dot-product of context and target vectors.\n",
        "\n",
        "The word co-occurence matrix is built a bit differently that counting co-occurences:\n",
        "* $d(i, j)$ is the distance from one word $i$ to another word $j$ in the corpus\n",
        "* Vanilla count: $X_{i,j} = \\left| \\left\\{ (i, j) : d(i, j) < \\textrm{window_size} \\right\\} \\right|$\n",
        "* Weighted count: $X_{i,j} = \\sum_{\\left\\{ (i, j) : d(i, j) < \\textrm{window_size} \\right\\}} \\frac{1}{d(i, j)} $\n",
        "\n",
        "\n",
        "Another sample weighting function is used for the cost function:\n",
        "* Given $x_{max} = 100$ a cut-off value, and $\\alpha = 0.75$\n",
        "* $x > x_{max} \\implies f(x) = 1$\n",
        "* $x \\leq x_{max} \\implies f(x) = \\left( \\frac{x}{x_{max}} \\right)^\\alpha$\n",
        "* This downweights the high co-occurence counts going for very frequent context words\n",
        "\n",
        "Given a vector dimension $d$, the parameters of the model are:\n",
        "* 2 matrices: $W, \\widetilde{W} \\in \\mathcal{M}_{V \\times d} $\n",
        "  * We note $w_i \\in \\mathbb{R}^d$ the $i$-th row of matrix $W$, it's a vector with $d$ dimensions\n",
        "* 2 vectors: $b, \\widetilde{b} \\in \\mathbb{R}^V$\n",
        "* We note $x \\cdot y$ the dot product between 2 vectors $x$ and $y$ of same dimensions\n",
        "\n",
        "GloVe models that the log of the co-occurences can be predicted with dot-product and biases:\n",
        "$$ \\textrm{log}\\left( X_{i,j} \\right) = w_i \\cdot \\widetilde{w}_j + b_i + \\widetilde{b}_j $$\n",
        "\n",
        "GloVe solves the following least-square optimization problem:\n",
        "$$W, \\widetilde{W}, b, \\widetilde{b} = \\textrm{Argmin} \\sum_{i=1}^V \\sum_{j=1}^V f(X_{i,j}) \\left( w_i \\cdot \\widetilde{w}_j + b_i + \\widetilde{b}_j - \\textrm{log}\\left( X_{i,j} \\right) \\right)^2 $$\n",
        "\n",
        "\n",
        "Given a word $i$, its word embedding is then $\\overrightarrow{i} = w_i + \\widetilde{w}_i$\n",
        "\n",
        "The optimization problem is solved by an optimizer named [AdaGrad](https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf) (Duchi et al., 2011), it is an adaptation of the stochastic gradient descent:\n",
        "* Batch of samples is going through the model\n",
        "* The loss is computed for this batch, based on model output\n",
        "* Parameters are chosen at random\n",
        "* These parameters are modified, based on the gradient of the loss with regard to these parameters\n",
        "* Repeat (GloVe is going through the whole corpus 100 times)"
      ],
      "metadata": {
        "id": "nfo9UHAdQs0W"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILI1yLQqQqFi"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fec3598-1a3a-4f1c-c9f1-62007b667982",
        "id": "YWH1x5y7QqFj"
      },
      "source": [
        "model = api.load('glove-wiki-gigaword-50')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AEc3nyfQqFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2990b7-80e5-4386-a346-cfabebaa09df"
      },
      "source": [
        "print(type(model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'gensim.models.keyedvectors.KeyedVectors'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9X2cv1wQqFk"
      },
      "source": [
        "Have a look at vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxG-NpzaQqFk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5dd4d97-2197-4622-ce15-43e04cd1c31e"
      },
      "source": [
        "model['taller']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.10266 ,  0.71612 ,  1.4231  , -0.9253  ,  0.64312 , -0.28203 ,\n",
              "        0.50574 , -0.52771 , -1.4088  ,  0.16786 ,  0.20419 , -0.59558 ,\n",
              "        0.29826 ,  0.11661 , -0.11096 ,  0.37027 ,  0.22684 ,  0.7704  ,\n",
              "        0.063899, -0.97135 , -2.0573  , -0.65494 , -0.26322 , -0.099344,\n",
              "        0.33814 ,  0.20605 ,  0.35168 ,  0.87609 ,  0.54054 , -0.31431 ,\n",
              "        1.2566  ,  0.071029,  0.77748 ,  0.052765,  0.10771 , -0.10713 ,\n",
              "        0.4045  ,  0.82837 , -0.49306 , -0.75354 , -0.3625  , -0.46964 ,\n",
              "        0.92376 ,  0.22864 , -0.077412, -0.42119 ,  0.053984, -1.574   ,\n",
              "       -0.45637 ,  0.42685 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSAwYF72QqFk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "3c959d60-3349-4611-89ba-4fd5b23eb725"
      },
      "source": [
        "model['sklsajhdgfjkhsosiuerhksjdhfkjsh']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key 'sklsajhdgfjkhsosiuerhksjdhfkjsh' not present\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-454ab67cdc10>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sklsajhdgfjkhsosiuerhksjdhfkjsh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \"\"\"\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \"\"\"\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'sklsajhdgfjkhsosiuerhksjdhfkjsh' not present\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVfBxksiQqFl"
      },
      "source": [
        "## Most similar words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLIsj8MQQqFl"
      },
      "source": [
        "The similarity between words is computed as the cosine similarity between the vectors representing these words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa11f27-6d59-4408-a35d-e691d8a051e5",
        "id": "8mRP9Xz_QqFl"
      },
      "source": [
        "model.similarity('investment', 'flower')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20200129"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KsBWVdhQqFl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaafe3f8-5fd4-412c-a979-4f2570e28a6d"
      },
      "source": [
        "model.most_similar(positive=['cat'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('dog', 0.9218006134033203),\n",
              " ('rabbit', 0.8487821221351624),\n",
              " ('monkey', 0.8041081428527832),\n",
              " ('rat', 0.7891963124275208),\n",
              " ('cats', 0.7865270972251892),\n",
              " ('snake', 0.7798910737037659),\n",
              " ('dogs', 0.7795814871788025),\n",
              " ('pet', 0.7792249917984009),\n",
              " ('mouse', 0.773166835308075),\n",
              " ('bite', 0.7728800177574158)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnv8GyGzQqFl"
      },
      "source": [
        "## Composition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjydfDtaQqFm"
      },
      "source": [
        "There are a few known vector equations, like:\n",
        "\n",
        "$\\overrightarrow{\\textrm{king}} - \\overrightarrow{\\textrm{man}} + \\overrightarrow{\\textrm{woman}} = \\overrightarrow{\\textrm{queen}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsQZZKJQQqFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeba8a85-92f7-40c9-bdda-d519a2205c12"
      },
      "source": [
        "model.most_similar(positive=['king', 'woman'], negative=['man'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.8523604273796082),\n",
              " ('throne', 0.7664334177970886),\n",
              " ('prince', 0.7592144012451172),\n",
              " ('daughter', 0.7473883628845215),\n",
              " ('elizabeth', 0.7460219860076904),\n",
              " ('princess', 0.7424570322036743),\n",
              " ('kingdom', 0.7337412238121033),\n",
              " ('monarch', 0.721449077129364),\n",
              " ('eldest', 0.7184861898422241),\n",
              " ('widow', 0.7099431157112122)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0rqHlltQqFm"
      },
      "source": [
        "$\\overrightarrow{\\textrm{paris}} - \\overrightarrow{\\textrm{france}} + \\overrightarrow{\\textrm{germany}} = \\overrightarrow{\\textrm{berlin}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqCvRxySQqFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d507f15-33dd-44fa-c2b3-c48d2b18e3c9"
      },
      "source": [
        "model.most_similar(positive=['paris', 'germany'], negative=['france'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('berlin', 0.9203965663909912),\n",
              " ('frankfurt', 0.8201637268066406),\n",
              " ('vienna', 0.8182448744773865),\n",
              " ('munich', 0.8152028918266296),\n",
              " ('hamburg', 0.7986699342727661),\n",
              " ('stockholm', 0.7764842510223389),\n",
              " ('budapest', 0.7678731083869934),\n",
              " ('warsaw', 0.7668997645378113),\n",
              " ('prague', 0.7664732933044434),\n",
              " ('amsterdam', 0.7555989027023315)]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4YnO7psQqFm"
      },
      "source": [
        "# Training with a corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAtJMK3UQqFm"
      },
      "source": [
        "As it is, the only _good_ implementation of GloVe is the original one in C. So we have to clone the git repository and compile it.\n",
        "\n",
        "This will work on Colab, won't probably work on your own laptop (needs a C compiler, bash shell, etc...)\n",
        "\n",
        "Other implementations have been proposed in Python, none of them made it into a _professional_ product such as SK-Learn or gensim. The ones I tried did not install on Python 3.10 and were unmaintained for 4 to 9 years."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download source code and compile\n",
        "\n",
        "!git clone https://github.com/stanfordnlp/glove\n",
        "!cd glove && make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wVBxZEFdJx8",
        "outputId": "035b2437-c745-46b3-98cd-a8ab7fb6de56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'glove'...\n",
            "remote: Enumerating objects: 656, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 656 (delta 36), reused 48 (delta 32), pack-reused 592\u001b[K\n",
            "Receiving objects: 100% (656/656), 245.96 KiB | 3.04 MiB/s, done.\n",
            "Resolving deltas: 100% (374/374), done.\n",
            "mkdir -p build\n",
            "gcc -c src/vocab_count.c -o build/vocab_count.o -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "gcc -c src/cooccur.c -o build/cooccur.o -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "\u001b[01m\u001b[Ksrc/cooccur.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kmerge_files\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/cooccur.c:180:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  180 |         \u001b[01;35m\u001b[Kfread(&new, sizeof(CREC), 1, fid[i])\u001b[m\u001b[K;\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/cooccur.c:190:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  190 |     \u001b[01;35m\u001b[Kfread(&new, sizeof(CREC), 1, fid[i])\u001b[m\u001b[K;\n",
            "      |     \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/cooccur.c:203:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  203 |         \u001b[01;35m\u001b[Kfread(&new, sizeof(CREC), 1, fid[i])\u001b[m\u001b[K;\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -c src/shuffle.c -o build/shuffle.o -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "\u001b[01m\u001b[Ksrc/shuffle.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kshuffle_merge\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/shuffle.c:96:17:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   96 |                 \u001b[01;35m\u001b[Kfread(&array[i], sizeof(CREC), 1, fid[j])\u001b[m\u001b[K;\n",
            "      |                 \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/shuffle.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kshuffle_by_chunks\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/shuffle.c:161:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  161 |         \u001b[01;35m\u001b[Kfread(&array[i], sizeof(CREC), 1, fin)\u001b[m\u001b[K;\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -c src/glove.c -o build/glove.o -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "\u001b[01m\u001b[Ksrc/glove.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kload_init_file\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/glove.c:86:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "   86 |         \u001b[01;35m\u001b[Kfread(&array[a], sizeof(real), 1, fin)\u001b[m\u001b[K;\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[Ksrc/glove.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[Kglove_thread\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[Ksrc/glove.c:182:9:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring return value of ‘\u001b[01m\u001b[Kfread\u001b[m\u001b[K’ declared with attribute ‘\u001b[01m\u001b[Kwarn_unused_result\u001b[m\u001b[K’ [\u001b[01;35m\u001b[K\u001b]8;;https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html#index-Wunused-result\u0007-Wunused-result\u001b]8;;\u0007\u001b[m\u001b[K]\n",
            "  182 |         \u001b[01;35m\u001b[Kfread(&cr, sizeof(CREC), 1, fin)\u001b[m\u001b[K;\n",
            "      |         \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "gcc -c src/common.c -o build/common.o -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "gcc build/vocab_count.o build/common.o -o build/vocab_count -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "gcc build/cooccur.o build/common.o -o build/cooccur -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "gcc build/shuffle.o build/common.o -o build/shuffle -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n",
            "gcc build/glove.o build/common.o -o build/glove -lm -pthread -O3 -march=native -funroll-loops -Wall -Wextra -Wpedantic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a look at the demo script\n",
        "# To train on our OWN corpus, we would need to modify the CORPUS variable to point to the big text file that contains all our corpus.\n",
        "!cat glove/demo.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKFwGpwWdc_l",
        "outputId": "b09c4365-1760-449d-b3ff-18dd07275999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#!/bin/bash\n",
            "set -e\n",
            "\n",
            "# Makes programs, downloads sample data, trains a GloVe model, and then evaluates it.\n",
            "# One optional argument can specify the language used for eval script: matlab, octave or [default] python\n",
            "\n",
            "make\n",
            "if [ ! -e text8 ]; then\n",
            "  if hash wget 2>/dev/null; then\n",
            "    wget http://mattmahoney.net/dc/text8.zip\n",
            "  else\n",
            "    curl -O http://mattmahoney.net/dc/text8.zip\n",
            "  fi\n",
            "  unzip text8.zip\n",
            "  rm text8.zip\n",
            "fi\n",
            "\n",
            "CORPUS=text8\n",
            "VOCAB_FILE=vocab.txt\n",
            "COOCCURRENCE_FILE=cooccurrence.bin\n",
            "COOCCURRENCE_SHUF_FILE=cooccurrence.shuf.bin\n",
            "BUILDDIR=build\n",
            "SAVE_FILE=vectors\n",
            "VERBOSE=2\n",
            "MEMORY=4.0\n",
            "VOCAB_MIN_COUNT=5\n",
            "VECTOR_SIZE=50\n",
            "MAX_ITER=15\n",
            "WINDOW_SIZE=15\n",
            "BINARY=2\n",
            "NUM_THREADS=8\n",
            "X_MAX=10\n",
            "if hash python 2>/dev/null; then\n",
            "    PYTHON=python\n",
            "else\n",
            "    PYTHON=python3\n",
            "fi\n",
            "\n",
            "echo\n",
            "echo \"$ $BUILDDIR/vocab_count -min-count $VOCAB_MIN_COUNT -verbose $VERBOSE < $CORPUS > $VOCAB_FILE\"\n",
            "$BUILDDIR/vocab_count -min-count $VOCAB_MIN_COUNT -verbose $VERBOSE < $CORPUS > $VOCAB_FILE\n",
            "echo \"$ $BUILDDIR/cooccur -memory $MEMORY -vocab-file $VOCAB_FILE -verbose $VERBOSE -window-size $WINDOW_SIZE < $CORPUS > $COOCCURRENCE_FILE\"\n",
            "$BUILDDIR/cooccur -memory $MEMORY -vocab-file $VOCAB_FILE -verbose $VERBOSE -window-size $WINDOW_SIZE < $CORPUS > $COOCCURRENCE_FILE\n",
            "echo \"$ $BUILDDIR/shuffle -memory $MEMORY -verbose $VERBOSE < $COOCCURRENCE_FILE > $COOCCURRENCE_SHUF_FILE\"\n",
            "$BUILDDIR/shuffle -memory $MEMORY -verbose $VERBOSE < $COOCCURRENCE_FILE > $COOCCURRENCE_SHUF_FILE\n",
            "echo \"$ $BUILDDIR/glove -save-file $SAVE_FILE -threads $NUM_THREADS -input-file $COOCCURRENCE_SHUF_FILE -x-max $X_MAX -iter $MAX_ITER -vector-size $VECTOR_SIZE -binary $BINARY -vocab-file $VOCAB_FILE -verbose $VERBOSE\"\n",
            "$BUILDDIR/glove -save-file $SAVE_FILE -threads $NUM_THREADS -input-file $COOCCURRENCE_SHUF_FILE -x-max $X_MAX -iter $MAX_ITER -vector-size $VECTOR_SIZE -binary $BINARY -vocab-file $VOCAB_FILE -verbose $VERBOSE\n",
            "if [ \"$CORPUS\" = 'text8' ]; then\n",
            "   if [ \"$1\" = 'matlab' ]; then\n",
            "       matlab -nodisplay -nodesktop -nojvm -nosplash < ./eval/matlab/read_and_evaluate.m 1>&2 \n",
            "   elif [ \"$1\" = 'octave' ]; then\n",
            "       octave < ./eval/octave/read_and_evaluate_octave.m 1>&2\n",
            "   else\n",
            "       echo \"$ $PYTHON eval/python/evaluate.py\"\n",
            "       $PYTHON eval/python/evaluate.py\n",
            "   fi\n",
            "fi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"brown\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc3LZxmzfaqg",
        "outputId": "71e9408e-fe0d-4043-88a3-6f001485276a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import brown\n",
        "with open(\"glove/brown.txt\", \"w\") as out:\n",
        "    for sent in brown.sents():\n",
        "        out.write(\" \".join(sent) + \"\\n\")"
      ],
      "metadata": {
        "id": "gRSV24HKfgDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script = \"\"\"#!/bin/bash\n",
        "set -e\n",
        "\n",
        "CORPUS=brown.txt\n",
        "VOCAB_FILE=vocab.txt\n",
        "COOCCURRENCE_FILE=cooccurrence.bin\n",
        "COOCCURRENCE_SHUF_FILE=cooccurrence.shuf.bin\n",
        "BUILDDIR=build\n",
        "SAVE_FILE=vectors\n",
        "VERBOSE=2\n",
        "MEMORY=4.0\n",
        "VOCAB_MIN_COUNT=5\n",
        "VECTOR_SIZE=50\n",
        "MAX_ITER=15\n",
        "WINDOW_SIZE=10\n",
        "BINARY=2\n",
        "NUM_THREADS=8\n",
        "X_MAX=10\n",
        "\n",
        "if hash python 2>/dev/null; then\n",
        "    PYTHON=python\n",
        "else\n",
        "    PYTHON=python3\n",
        "fi\n",
        "\n",
        "echo\n",
        "echo \"$ $BUILDDIR/vocab_count -min-count $VOCAB_MIN_COUNT -verbose $VERBOSE < $CORPUS > $VOCAB_FILE\"\n",
        "$BUILDDIR/vocab_count -min-count $VOCAB_MIN_COUNT -verbose $VERBOSE < $CORPUS > $VOCAB_FILE\n",
        "echo \"$ $BUILDDIR/cooccur -memory $MEMORY -vocab-file $VOCAB_FILE -verbose $VERBOSE -window-size $WINDOW_SIZE < $CORPUS > $COOCCURRENCE_FILE\"\n",
        "$BUILDDIR/cooccur -memory $MEMORY -vocab-file $VOCAB_FILE -verbose $VERBOSE -window-size $WINDOW_SIZE < $CORPUS > $COOCCURRENCE_FILE\n",
        "echo \"$ $BUILDDIR/shuffle -memory $MEMORY -verbose $VERBOSE < $COOCCURRENCE_FILE > $COOCCURRENCE_SHUF_FILE\"\n",
        "$BUILDDIR/shuffle -memory $MEMORY -verbose $VERBOSE < $COOCCURRENCE_FILE > $COOCCURRENCE_SHUF_FILE\n",
        "echo \"$ $BUILDDIR/glove -save-file $SAVE_FILE -threads $NUM_THREADS -input-file $COOCCURRENCE_SHUF_FILE -x-max $X_MAX -iter $MAX_ITER -vector-size $VECTOR_SIZE -binary $BINARY -vocab-file $VOCAB_FILE -verbose $VERBOSE\"\n",
        "$BUILDDIR/glove -save-file $SAVE_FILE -threads $NUM_THREADS -input-file $COOCCURRENCE_SHUF_FILE -x-max $X_MAX -iter $MAX_ITER -vector-size $VECTOR_SIZE -binary $BINARY -vocab-file $VOCAB_FILE -verbose $VERBOSE\n",
        "if [ \"$CORPUS\" = 'text8' ]; then\n",
        "   if [ \"$1\" = 'matlab' ]; then\n",
        "       matlab -nodisplay -nodesktop -nojvm -nosplash < ./eval/matlab/read_and_evaluate.m 1>&2\n",
        "   elif [ \"$1\" = 'octave' ]; then\n",
        "       octave < ./eval/octave/read_and_evaluate_octave.m 1>&2\n",
        "   else\n",
        "       echo \"$ $PYTHON eval/python/evaluate.py\"\n",
        "       $PYTHON eval/python/evaluate.py\n",
        "   fi\n",
        "fi\"\"\"\n",
        "\n",
        "with open(\"glove/script.sh\", \"w\") as out:\n",
        "    out.write(script)"
      ],
      "metadata": {
        "id": "RcBP-pjzgCHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the script - take some time\n",
        "!cd glove && chmod a+x script.sh && ./script.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ-TjBncdoNa",
        "outputId": "3c8ad07c-367b-44b7-84bd-dc1ad753762d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "$ build/vocab_count -min-count 5 -verbose 2 < brown.txt > vocab.txt\n",
            "BUILDING VOCABULARY\n",
            "Processed 0 tokens.\u001b[11G100000 tokens.\u001b[11G200000 tokens.\u001b[11G300000 tokens.\u001b[11G400000 tokens.\u001b[11G500000 tokens.\u001b[11G600000 tokens.\u001b[11G700000 tokens.\u001b[11G800000 tokens.\u001b[11G900000 tokens.\u001b[11G1000000 tokens.\u001b[11G1100000 tokens.\u001b[0GProcessed 1161192 tokens.\n",
            "Counted 56057 unique words.\n",
            "Truncating vocabulary at min count 5.\n",
            "Using vocabulary of size 15173.\n",
            "\n",
            "$ build/cooccur -memory 4.0 -vocab-file vocab.txt -verbose 2 -window-size 10 < brown.txt > cooccurrence.bin\n",
            "COUNTING COOCCURRENCES\n",
            "window size: 10\n",
            "context: symmetric\n",
            "max product: 13752509\n",
            "overflow length: 38028356\n",
            "Reading vocab from file \"vocab.txt\"...loaded 15173 words.\n",
            "Building lookup table...table contains 52490245 elements.\n",
            "Processing token: 0\u001b[19G100000\u001b[19G200000\u001b[19G300000\u001b[19G400000\u001b[19G500000\u001b[19G600000\u001b[19G700000\u001b[19G800000\u001b[19G900000\u001b[19G1000000\u001b[19G1100000\u001b[0GProcessed 1161192 tokens.\n",
            "Writing cooccurrences to disk........2 files in total.\n",
            "Merging cooccurrence files: processed 0 lines.\u001b[39G100000 lines.\u001b[39G200000 lines.\u001b[39G300000 lines.\u001b[39G400000 lines.\u001b[39G500000 lines.\u001b[39G600000 lines.\u001b[39G700000 lines.\u001b[39G800000 lines.\u001b[39G900000 lines.\u001b[39G1000000 lines.\u001b[39G1100000 lines.\u001b[39G1200000 lines.\u001b[39G1300000 lines.\u001b[39G1400000 lines.\u001b[39G1500000 lines.\u001b[39G1600000 lines.\u001b[39G1700000 lines.\u001b[39G1800000 lines.\u001b[39G1900000 lines.\u001b[39G2000000 lines.\u001b[39G2100000 lines.\u001b[39G2200000 lines.\u001b[39G2300000 lines.\u001b[39G2400000 lines.\u001b[39G2500000 lines.\u001b[39G2600000 lines.\u001b[39G2700000 lines.\u001b[39G2800000 lines.\u001b[39G2900000 lines.\u001b[39G3000000 lines.\u001b[39G3100000 lines.\u001b[39G3200000 lines.\u001b[39G3300000 lines.\u001b[39G3400000 lines.\u001b[39G3500000 lines.\u001b[39G3600000 lines.\u001b[39G3700000 lines.\u001b[39G3800000 lines.\u001b[0GMerging cooccurrence files: processed 3803962 lines.\n",
            "\n",
            "$ build/shuffle -memory 4.0 -verbose 2 < cooccurrence.bin > cooccurrence.shuf.bin\n",
            "Using random seed 1708685933\n",
            "SHUFFLING COOCCURRENCES\n",
            "array size: 255013683\n",
            "Shuffling by chunks: processed 0 lines.\u001b[22Gprocessed 3803962 lines.\n",
            "Wrote 1 temporary file(s).\n",
            "Merging temp files: processed 0 lines.\u001b[31G3803962 lines.\u001b[0GMerging temp files: processed 3803962 lines.\n",
            "\n",
            "$ build/glove -save-file vectors -threads 8 -input-file cooccurrence.shuf.bin -x-max 10 -iter 15 -vector-size 50 -binary 2 -vocab-file vocab.txt -verbose 2\n",
            "TRAINING MODEL\n",
            "Read 3803962 lines.\n",
            "Initializing parameters...Using random seed 1708685936\n",
            "done.\n",
            "vector size: 50\n",
            "vocab size: 15173\n",
            "x_max: 10.000000\n",
            "alpha: 0.750000\n",
            "02/23/24 - 10:59.00AM, iter: 001, cost: 0.071721\n",
            "02/23/24 - 10:59.04AM, iter: 002, cost: 0.051827\n",
            "02/23/24 - 10:59.09AM, iter: 003, cost: 0.047331\n",
            "02/23/24 - 10:59.13AM, iter: 004, cost: 0.042960\n",
            "02/23/24 - 10:59.19AM, iter: 005, cost: 0.038655\n",
            "02/23/24 - 10:59.25AM, iter: 006, cost: 0.035224\n",
            "02/23/24 - 10:59.29AM, iter: 007, cost: 0.032592\n",
            "02/23/24 - 10:59.33AM, iter: 008, cost: 0.030760\n",
            "02/23/24 - 10:59.38AM, iter: 009, cost: 0.029356\n",
            "02/23/24 - 10:59.42AM, iter: 010, cost: 0.028224\n",
            "02/23/24 - 10:59.46AM, iter: 011, cost: 0.027297\n",
            "02/23/24 - 10:59.51AM, iter: 012, cost: 0.026478\n",
            "02/23/24 - 10:59.55AM, iter: 013, cost: 0.025820\n",
            "02/23/24 - 10:59.59AM, iter: 014, cost: 0.025203\n",
            "02/23/24 - 11:00.05AM, iter: 015, cost: 0.024666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -alh glove/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsCeGoDVhDJQ",
        "outputId": "dbbdd96b-8606-4fac-9a4b-bbb7fb91cd81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 141M\n",
            "drwxr-xr-x 6 root root 4.0K Feb 23 11:00 .\n",
            "drwxr-xr-x 1 root root 4.0K Feb 23 10:58 ..\n",
            "-rw-r--r-- 1 root root 5.9M Feb 23 10:58 brown.txt\n",
            "drwxr-xr-x 2 root root 4.0K Feb 23 10:58 build\n",
            "-rw-r--r-- 1 root root  59M Feb 23 10:58 cooccurrence.bin\n",
            "-rw-r--r-- 1 root root  59M Feb 23 10:58 cooccurrence.shuf.bin\n",
            "-rwxr-xr-x 1 root root 2.2K Feb 23 10:58 demo.sh\n",
            "drwxr-xr-x 6 root root 4.0K Feb 23 10:58 eval\n",
            "drwxr-xr-x 8 root root 4.0K Feb 23 10:58 .git\n",
            "-rw-r--r-- 1 root root  395 Feb 23 10:58 .gitignore\n",
            "-rw-r--r-- 1 root root  12K Feb 23 10:58 LICENSE\n",
            "-rw-r--r-- 1 root root 1.8K Feb 23 10:58 Makefile\n",
            "-rwxr-xr-x 1 root root 5.6K Feb 23 10:58 randomization.test.sh\n",
            "-rw-r--r-- 1 root root 4.1K Feb 23 10:58 README.md\n",
            "-rwxr-xr-x 1 root root 1.8K Feb 23 10:58 script.sh\n",
            "drwxr-xr-x 2 root root 4.0K Feb 23 10:58 src\n",
            "-rw-r--r-- 1 root root  266 Feb 23 10:58 .travis.yml\n",
            "-rw-r--r-- 1 root root  12M Feb 23 11:00 vectors.bin\n",
            "-rw-r--r-- 1 root root 7.1M Feb 23 11:00 vectors.txt\n",
            "-rw-r--r-- 1 root root 160K Feb 23 10:58 vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "glove = KeyedVectors.load_word2vec_format(\"glove/vectors.txt\", binary=False, no_header=True)"
      ],
      "metadata": {
        "id": "kW2eF2aNdoJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove[\"organization\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WD8McmwCdoF3",
        "outputId": "4e34984e-700d-4194-9c3c-67267b5655b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.418764,  0.421518,  0.27538 , -0.397474,  0.142214, -0.242316,\n",
              "        0.053651, -0.468822,  0.537759,  0.044231,  0.520412, -0.642135,\n",
              "        0.011442, -0.209167,  0.086259, -0.607625,  0.187064, -0.055518,\n",
              "        0.049631,  0.393111,  0.245218, -0.576439, -0.269007, -0.652524,\n",
              "        0.409631,  0.212102, -0.031077, -0.336079,  0.227747, -0.207841,\n",
              "        0.580933,  0.675261, -0.017512, -0.324828,  0.151802,  0.069465,\n",
              "        0.301503, -0.056689, -0.344672, -0.201804,  0.276245,  0.375324,\n",
              "        0.160446,  0.201178, -0.097592, -0.334347,  0.233188,  0.528185,\n",
              "        0.160585,  0.249094], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove.most_similar(positive=\"organization\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL6b8x7aiDaX",
        "outputId": "6b9f6753-4445-4cd0-83a4-769468abbbb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('relations', 0.6864994764328003),\n",
              " ('national', 0.6445522904396057),\n",
              " ('church', 0.6442544460296631),\n",
              " ('industry', 0.6423518657684326),\n",
              " ('institution', 0.6338604092597961),\n",
              " ('community', 0.625983715057373),\n",
              " ('group', 0.6190690398216248),\n",
              " ('values', 0.6110990047454834),\n",
              " ('power', 0.6086166501045227),\n",
              " ('American', 0.6071235537528992)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym-ObaSZQqFo"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE6iQc7BQqFo"
      },
      "source": [
        "Evaluation is conducted by checking if a list in similarities in words (given by human) are reflected well as similarities in between vectors.\n",
        "\n",
        "Results are bad, remember we used a tiny corpus, with a tiny vocabulary, small vector dimension, so it won't have seen much of the \"world knowledge\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uO_-AWRZQqFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce6ca98-1034-4003-f2ae-d0a98004b63c"
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "score, detailed_results = glove.evaluate_word_analogies(datapath('questions-words.txt'))\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.022577455504284773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkuahKZQQqFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bdb8153-d3fb-4b46-db2a-87bb0239708d"
      },
      "source": [
        "glove.evaluate_word_pairs(datapath('wordsim353.tsv'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PearsonRResult(statistic=0.13273228624343783, pvalue=0.028916418693611702),\n",
              " SignificanceResult(statistic=0.11226196239338654, pvalue=0.06498516182129667),\n",
              " 23.229461756373937)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word2Vec"
      ],
      "metadata": {
        "id": "vpSvQTTMQkBn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "067nMMnueMZq"
      },
      "source": [
        "Word2Vec is a model described by Mikolov et al in 2013, it is as well a patented algorithm by Google:\n",
        "* \"Efficient Estimation of Word Representations in Vector Space\" [ArXiv](https://arxiv.org/abs/1301.3781)\n",
        "* \"Distributed representations of words and phrases and their compositionality\" [ArXiv](https://arxiv.org/abs/1310.4546)\n",
        "* \"Computing numeric representations of words in a high-dimensional space\" [Patent](https://patents.google.com/patent/US9037464B1/en)\n",
        "\n",
        "A neural network with 1 hidden layer trains on the task of predicting a word given a few context words:\n",
        "* For example, with a window of size 5\n",
        "* The sample is a part of a sentence \"my blue ship sails faster\"\n",
        " * Context words: `my` `blue` `sails` `faster`\n",
        " * Central word: `ship`\n",
        "* **Skip-Gram**: predict `my` `blue` `sails` `faster` from `ship`\n",
        "* From a complete corpus, extract as many samples as possible\n",
        "* The sample loss is the difference between predicted probabilities of each word of the dictionary versus ground truth (log likelyhood)\n",
        "* Minimize the loss over all the dataset\n",
        "\n",
        "Once the neural network is trained:\n",
        "* Read the weights of the hidden layer as word embeddings\n",
        "* This is also the values in the neurons of the hidden layer when the word is given as input (green area on the illustration)\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/1*HQeN5Q9FhN_XPbM4QuWIRg.jpeg\"></img>\n",
        "\n",
        "Image source: https://medium.com/@zeeshanmulla/word-embeddings-in-natural-language-processing-nlp-5be7d6fb1d73\n",
        "\n",
        "The contribution of Mikolov et al. deals mainly with optimizations of the training so that it is actually tractable. We will not enter into these details.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFwuc5FFbz_R"
      },
      "source": [
        "# Use an existing model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vUZKd-Xb2t5"
      },
      "source": [
        "Considering the effort, it is worth using a pretrained model.\n",
        "\n",
        "What is a pretrained model:\n",
        "* a dictionary\n",
        "* each key is a word\n",
        "* each value is a vector\n",
        "\n",
        "**Warning**\n",
        "\n",
        "It will download **1.6GB** of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IijFUUt0W3SD"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re5XOxOTY8hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d99c83db-342b-4f00-fd4c-fb8218793a01"
      },
      "source": [
        "model = api.load('word2vec-google-news-300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQIVJAcnfIe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fce639a5-e8f0-43f5-f697-7aa770be5dd0"
      },
      "source": [
        "print(type(model))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'gensim.models.keyedvectors.KeyedVectors'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxNlpZTKcQ35"
      },
      "source": [
        "Have a look at vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_7jKnaYaW1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e937d0-3fa4-41fb-bafe-a819ffa51721"
      },
      "source": [
        "model['taller']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.40234375e-01,  3.85742188e-02,  8.59375000e-02, -1.64062500e-01,\n",
              "        1.96289062e-01,  4.51660156e-02,  4.37500000e-01,  2.43164062e-01,\n",
              "        1.79687500e-01,  3.67187500e-01,  5.07812500e-01,  1.25976562e-01,\n",
              "        1.31835938e-01, -5.95703125e-02,  1.49414062e-01, -1.88476562e-01,\n",
              "        1.02539062e-01, -7.86132812e-02,  5.85937500e-02,  1.14746094e-01,\n",
              "       -4.45312500e-01,  1.03149414e-02, -1.25000000e-01,  1.55273438e-01,\n",
              "       -2.96875000e-01, -1.60156250e-01, -1.81640625e-01, -3.71093750e-02,\n",
              "        1.56250000e-01, -2.39257812e-01,  1.33789062e-01,  2.11914062e-01,\n",
              "        1.05957031e-01, -4.29687500e-01,  2.71484375e-01, -2.75390625e-01,\n",
              "        2.11914062e-01,  2.63671875e-01, -1.50390625e-01,  2.15820312e-01,\n",
              "        4.08203125e-01, -3.06640625e-01, -1.88446045e-03, -2.61718750e-01,\n",
              "        1.51367188e-01, -2.03125000e-01, -2.61718750e-01, -3.75976562e-02,\n",
              "        6.98242188e-02, -3.80859375e-01, -1.66992188e-01, -3.37890625e-01,\n",
              "       -4.21875000e-01, -3.98437500e-01,  2.98828125e-01,  1.76757812e-01,\n",
              "        5.81054688e-02, -1.52343750e-01,  4.97436523e-03, -2.43164062e-01,\n",
              "       -4.88281250e-02, -3.39843750e-01, -5.76171875e-02, -4.80468750e-01,\n",
              "        9.57031250e-02,  1.75781250e-01, -1.17187500e-01,  8.88671875e-02,\n",
              "       -8.15429688e-02,  5.74218750e-01,  1.73828125e-01,  1.30615234e-02,\n",
              "       -6.15234375e-02, -1.48437500e-01, -3.28125000e-01,  3.80859375e-02,\n",
              "       -2.55126953e-02,  7.37304688e-02,  2.59765625e-01,  6.73828125e-02,\n",
              "       -9.27734375e-02,  1.39648438e-01, -7.03125000e-02,  1.95312500e-01,\n",
              "       -3.14453125e-01,  1.57226562e-01, -9.03320312e-02, -2.27050781e-02,\n",
              "        3.35937500e-01,  2.50244141e-02, -2.30468750e-01, -1.61132812e-01,\n",
              "       -3.43750000e-01,  3.33984375e-01,  1.19628906e-01, -4.00390625e-01,\n",
              "        2.19726562e-01, -1.46484375e-01, -1.89453125e-01, -4.39453125e-01,\n",
              "        4.88281250e-02, -1.37695312e-01,  5.07812500e-01,  1.79687500e-01,\n",
              "        2.69531250e-01,  1.63085938e-01, -1.51367188e-01, -1.42578125e-01,\n",
              "       -4.53125000e-01,  6.22558594e-02,  9.22851562e-02, -7.71484375e-02,\n",
              "       -1.56250000e-01,  2.09960938e-01,  9.57031250e-02, -6.83593750e-02,\n",
              "        9.42382812e-02, -2.46093750e-01,  2.16064453e-02, -2.12890625e-01,\n",
              "       -4.39453125e-01, -5.68847656e-02, -1.03027344e-01,  2.52685547e-02,\n",
              "       -2.40234375e-01, -5.46875000e-02,  1.03027344e-01, -9.17968750e-02,\n",
              "        4.61425781e-02,  1.03759766e-03, -3.10058594e-02,  1.40625000e-01,\n",
              "       -1.51367188e-01,  1.64794922e-02,  1.38549805e-02,  1.55273438e-01,\n",
              "        1.28906250e-01, -6.29882812e-02, -9.03320312e-02,  1.14746094e-01,\n",
              "        7.12890625e-02, -6.64062500e-02, -2.00195312e-01, -2.96875000e-01,\n",
              "        2.36328125e-01, -1.04980469e-01, -6.07910156e-02, -2.81250000e-01,\n",
              "        1.39648438e-01,  1.53808594e-02,  3.88183594e-02, -1.44531250e-01,\n",
              "       -3.47656250e-01,  9.42382812e-02, -1.38671875e-01,  4.62890625e-01,\n",
              "       -3.14453125e-01, -2.31445312e-01,  1.12304688e-01, -3.22265625e-02,\n",
              "        2.42187500e-01,  8.49609375e-02,  3.57421875e-01, -1.44531250e-01,\n",
              "        1.16210938e-01, -2.98828125e-01,  1.59179688e-01,  6.98242188e-02,\n",
              "       -3.08593750e-01,  8.85009766e-03, -2.92968750e-01,  1.13769531e-01,\n",
              "       -5.37109375e-02, -1.11816406e-01, -1.92382812e-01,  2.79541016e-02,\n",
              "        9.42382812e-02, -2.23632812e-01, -1.36718750e-01,  1.96289062e-01,\n",
              "       -9.17968750e-02, -2.50000000e-01, -1.23046875e-01, -2.04101562e-01,\n",
              "       -9.71679688e-02, -5.62500000e-01,  2.83203125e-01, -1.56250000e-01,\n",
              "       -2.05078125e-01, -4.92187500e-01,  3.96484375e-01, -3.71093750e-01,\n",
              "        3.34472656e-02, -4.95910645e-04,  2.06054688e-01,  1.62109375e-01,\n",
              "        1.10839844e-01,  1.83105469e-02, -7.22656250e-02, -2.59765625e-01,\n",
              "        1.31835938e-01,  9.42382812e-02,  3.68652344e-02,  5.29785156e-02,\n",
              "        1.07910156e-01, -1.05468750e-01,  4.27734375e-01, -3.14453125e-01,\n",
              "       -1.27929688e-01,  2.08984375e-01, -2.83203125e-01,  1.89453125e-01,\n",
              "        3.19824219e-02, -3.07617188e-02, -1.42822266e-02,  6.98242188e-02,\n",
              "       -3.22265625e-01,  2.95410156e-02,  2.41699219e-02,  2.10937500e-01,\n",
              "       -1.19628906e-02,  1.94335938e-01, -7.71484375e-02, -3.20312500e-01,\n",
              "       -1.85394287e-03, -3.84765625e-01, -2.26562500e-01,  2.63671875e-01,\n",
              "        8.30078125e-02,  2.27539062e-01,  4.51660156e-03, -6.22558594e-02,\n",
              "        1.68945312e-01,  4.55078125e-01,  2.43164062e-01,  9.96093750e-02,\n",
              "       -3.33984375e-01, -6.05468750e-01,  2.30468750e-01, -1.89208984e-02,\n",
              "        1.19140625e-01,  2.07031250e-01,  2.79235840e-03, -1.89453125e-01,\n",
              "       -6.68945312e-02,  1.56250000e-01, -2.26562500e-01, -2.28271484e-02,\n",
              "       -5.44433594e-02,  5.44433594e-02,  4.16015625e-01, -1.45507812e-01,\n",
              "        1.22558594e-01,  2.20703125e-01,  3.35937500e-01, -1.10351562e-01,\n",
              "       -2.63671875e-01,  2.61718750e-01, -1.37695312e-01,  3.41796875e-01,\n",
              "        8.78906250e-02,  8.64257812e-02, -3.43750000e-01, -4.24804688e-02,\n",
              "        2.27539062e-01,  2.24609375e-01, -1.59179688e-01,  1.58203125e-01,\n",
              "       -2.71484375e-01, -1.60156250e-01, -1.70898438e-01,  6.98242188e-02,\n",
              "        8.20312500e-02, -1.09863281e-01,  2.27539062e-01, -6.15234375e-02,\n",
              "       -2.08984375e-01,  2.35595703e-02,  1.67968750e-01,  2.75878906e-02,\n",
              "        7.27539062e-02,  1.42578125e-01,  2.85644531e-02, -1.71875000e-01,\n",
              "        6.29882812e-02, -2.19726562e-02, -4.39453125e-01, -2.25585938e-01,\n",
              "        2.47070312e-01, -1.08398438e-01,  1.10351562e-01,  5.24902344e-02,\n",
              "       -1.47460938e-01, -1.44531250e-01, -2.88085938e-02,  1.94335938e-01,\n",
              "       -3.63281250e-01, -2.85156250e-01, -2.21679688e-01,  6.17675781e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bebeHpCNbP3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "ccf5ea0b-cfd9-46dd-fa4f-cc321b5e63df"
      },
      "source": [
        "model['sklsajhdgfjkhsosiuerhksjdhfkjsh']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key 'sklsajhdgfjkhsosiuerhksjdhfkjsh' not present\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-454ab67cdc10>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sklsajhdgfjkhsosiuerhksjdhfkjsh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \"\"\"\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \"\"\"\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'sklsajhdgfjkhsosiuerhksjdhfkjsh' not present\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBsC9LOGcUdZ"
      },
      "source": [
        "## Most similar words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71QRxw9-gzRt"
      },
      "source": [
        "The similarity between words is computed as the cosine similarity between the vectors representing these words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0-WruQtfSxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817cf09d-0076-4ecd-8de1-8826ba615d04"
      },
      "source": [
        "model.similarity('investment', 'flower')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.02175734"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qPgl4PDa3_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e4899e-f492-462e-ac4f-132cf21bd95f"
      },
      "source": [
        "model.most_similar(positive=['cat'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cats', 0.8099379539489746),\n",
              " ('dog', 0.760945737361908),\n",
              " ('kitten', 0.7464985251426697),\n",
              " ('feline', 0.7326234579086304),\n",
              " ('beagle', 0.7150582671165466),\n",
              " ('puppy', 0.7075453400611877),\n",
              " ('pup', 0.6934291124343872),\n",
              " ('pet', 0.6891531348228455),\n",
              " ('felines', 0.6755931973457336),\n",
              " ('chihuahua', 0.6709762215614319)]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5cakuhAg9TW"
      },
      "source": [
        "## Composition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InPiSvqpgGQB"
      },
      "source": [
        "There are a few known vector equations, like:\n",
        "\n",
        "$\\overrightarrow{\\textrm{king}} - \\overrightarrow{\\textrm{man}} + \\overrightarrow{\\textrm{woman}} = \\overrightarrow{\\textrm{queen}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNLOc-2EfdzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "288b1dc3-9667-4b58-df6b-89cf85905344"
      },
      "source": [
        "model.most_similar(positive=['king', 'woman'], negative=['man'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7118193507194519),\n",
              " ('monarch', 0.6189674139022827),\n",
              " ('princess', 0.5902431011199951),\n",
              " ('crown_prince', 0.5499460697174072),\n",
              " ('prince', 0.5377321839332581),\n",
              " ('kings', 0.5236844420433044),\n",
              " ('Queen_Consort', 0.5235945582389832),\n",
              " ('queens', 0.5181134343147278),\n",
              " ('sultan', 0.5098593831062317),\n",
              " ('monarchy', 0.5087411999702454)]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX11mCr2hGgS"
      },
      "source": [
        "$\\overrightarrow{\\textrm{paris}} - \\overrightarrow{\\textrm{france}} + \\overrightarrow{\\textrm{germany}} = \\overrightarrow{\\textrm{berlin}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFjU1Y-ofxI2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76cb208-85bf-479b-9132-bf0b2d79f73c"
      },
      "source": [
        "model.most_similar(positive=['paris', 'germany'], negative=['france'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('berlin', 0.48413652181625366),\n",
              " ('german', 0.4656967222690582),\n",
              " ('lindsay_lohan', 0.45592251420021057),\n",
              " ('heidi', 0.4484093487262726),\n",
              " ('switzerland', 0.44479838013648987),\n",
              " ('lil_kim', 0.44306042790412903),\n",
              " ('las_vegas', 0.4418063759803772),\n",
              " ('christina', 0.43938425183296204),\n",
              " ('joel', 0.4375365674495697),\n",
              " ('russia', 0.43744248151779175)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqZeElorJRvO"
      },
      "source": [
        "# Training with a corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ekrZdbnyAtx"
      },
      "source": [
        "We will use the [Brown Corpus](http://korpus.uib.no/icame/manuals/BROWN/INDEX.HTM) as illustration.\n",
        "\n",
        "This corpus is made of books published in 1961, written by native English speakers.\n",
        "\n",
        "We will generate 100-dims vector for the words in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GMheswfJLl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb55e255-0c7b-4a43-ad31-e2959fe57df8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('brown')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIdbU5rvJ0yt"
      },
      "source": [
        "from gensim.models.word2vec import BrownCorpus\n",
        "\n",
        "brown = BrownCorpus('/root/nltk_data/corpora/brown')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlwhC7Cry9hr"
      },
      "source": [
        "It is a list of tokenized sentences. Each word his also flagged with its Part-of-Speech tag (POS).\n",
        "\n",
        "* `pp` = personal pronoun\n",
        "* `vb` = verb\n",
        "* etc..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD5i4WE_ytOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406e5ee3-5b63-4eb7-c612-d2058777b977"
      },
      "source": [
        "all_brown = list(brown)\n",
        "print(all_brown[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['from/in', 'time/nn', 'to/in', 'time/nn', 'the/at', 'medium/nn', 'mentions/vb', 'other/ap', 'people/nn', 'around/in', 'him/pp', 'who/wp', 'were/be', 'on/in', 'the/at', 'other/ap', 'side/nn', 'and/cc', 'reports/vb', 'what/wd', 'they/pp', 'are/be', 'saying/vb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CN2cytZgzSac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "791b105d-ed1f-4f06-a293-347dbe62ef95"
      },
      "source": [
        "print(f'Brown Corpus contains {len(all_brown)} sentences, and a total of {sum(map(len, brown))} tokens.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brown Corpus contains 57160 sentences, and a total of 1008788 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def untag(tokens: list[str]) -> list[str]:\n",
        "    return [x.split(\"/\")[0] for x in tokens]"
      ],
      "metadata": {
        "id": "v2VB4lb5lMM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzoKRKD5KFaq"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v = Word2Vec(\n",
        "    sentences=list(map(untag, BrownCorpus('/root/nltk_data/corpora/brown'))),\n",
        "    vector_size=100,\n",
        "    window=3,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9xA7jmHz2tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e6f99f-4ad1-459a-9679-809ff0c4563f"
      },
      "source": [
        "print(f'Word2Vec created for a vocabulary of {len(w2v.wv.key_to_index)} unique terms.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec created for a vocabulary of 14202 unique terms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anvn5P6SLJdS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae037a4-3125-4579-f289-671dfd714095"
      },
      "source": [
        "w2v.wv['organization']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.42340508,  0.06747078, -0.11929397,  0.03149147,  0.15471587,\n",
              "       -0.21006505,  0.0872668 ,  0.82391083, -0.35102427, -0.4539076 ,\n",
              "       -0.19054264, -0.55677223, -0.45158467,  0.15934059, -0.03269314,\n",
              "       -0.16204906,  0.09252246,  0.00719921, -0.10918552, -0.73837686,\n",
              "        0.01997648, -0.24877486,  0.21343672,  0.01848866, -0.2573498 ,\n",
              "        0.24949244, -0.25260803, -0.31156856, -0.03275163,  0.15680185,\n",
              "        0.34803045, -0.29334188, -0.12168016, -0.5624341 ,  0.17531586,\n",
              "        0.30134255,  0.4372661 ,  0.15200591,  0.12052317, -0.33997062,\n",
              "        0.3541588 , -0.31935936, -0.15808977,  0.41504133,  0.26788163,\n",
              "       -0.1412938 , -0.5464312 , -0.20193546,  0.6154787 , -0.14021602,\n",
              "       -0.02955584, -0.68297845,  0.08599978,  0.10354364, -0.33649576,\n",
              "        0.2756025 ,  0.24888946, -0.30664644, -0.3590795 ,  0.26671532,\n",
              "        0.28736857,  0.2286618 ,  0.39367908, -0.12574787,  0.26775005,\n",
              "        0.5035551 ,  0.09781768,  0.5472353 , -0.42781058,  0.04521145,\n",
              "        0.29530096,  0.07117656,  0.33902082, -0.02691504,  0.16969131,\n",
              "        0.10870585,  0.04669235,  0.04843257, -0.24577494, -0.2220564 ,\n",
              "       -0.38973108, -0.32828048, -0.06144468, -0.01832295, -0.08485661,\n",
              "       -0.22431187,  0.1465764 , -0.0713556 ,  0.156717  ,  0.02116979,\n",
              "        0.36693478,  0.35522747,  0.02270136,  0.04337271,  0.4176099 ,\n",
              "        0.49899068,  0.24871777, -0.54630107,  0.0096318 ,  0.26844153],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuov2v5L0F8e"
      },
      "source": [
        "Now we can evaluate and see that it is not performing well.\n",
        "\n",
        "We would need:\n",
        "* More data\n",
        "* More processing to train the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kpivj_AXMbJC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "980a0119-6eee-40c7-c41e-81f01f8d59e6"
      },
      "source": [
        "w2v.wv.most_similar(positive=['organization'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('existence', 0.9672751426696777),\n",
              " ('share', 0.9583585858345032),\n",
              " ('aid', 0.9552187919616699),\n",
              " ('influence', 0.9538760185241699),\n",
              " ('society', 0.9504542350769043),\n",
              " ('degree', 0.9504178166389465),\n",
              " ('value', 0.9485926628112793),\n",
              " ('industry', 0.9477483034133911),\n",
              " ('portion', 0.9469727873802185),\n",
              " ('method', 0.946385383605957)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIkI2vvl1SXp"
      },
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOQV_Nof1TvR"
      },
      "source": [
        "Evaluation is conducted by checking if a list in similarities in words (given by human) are reflected well as similarities in between vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It_8WtgSx4eR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa709847-3e82-4a94-f848-77186c7e59d4"
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "score, detailed_results = w2v.wv.evaluate_word_analogies(datapath('questions-words.txt'))\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.03140862944162436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZM5R8_Qb04xv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9575288-5978-4285-df56-47ba597569d4"
      },
      "source": [
        "w2v.wv.evaluate_word_pairs(datapath('wordsim353.tsv'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PearsonRResult(statistic=0.07689446978435996, pvalue=0.20448012052253928),\n",
              " SignificanceResult(statistic=0.1161781634671872, pvalue=0.05475588633792315),\n",
              " 22.379603399433428)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1cD9xtC10sZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}